# -*- coding: utf-8 -*-
"""AB_NYC_2019.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OpyoHVvIESTFhNj3vFD5PhLj9gH3pIRP

# **New York City Airbnb Listing Dataset Analysis**

**This dataset is related to Airbnb listings in New York City, providing information about various aspects of rental properties and hosts.**
"""

import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv(r"/content/AB_NYC_2019 (1).csv")

df.head()

"""## **Data Cleaning**"""

df.shape

df.dtypes

df.isna().sum()

columns_to_drop = ['id', 'host_id', 'host_name', 'last_review']
df = df.drop(columns=columns_to_drop)

df['reviews_per_month'].fillna(0, inplace=True)
df.dropna(inplace=True)

df

df.isna().sum()

df.head()

df['price_per_night'] = df['price'] / df['minimum_nights']

df

"""# **Exploratory Data Analysis**"""

sns.set(style='whitegrid')
sns.set_palette('magma')

plt.figure(figsize=(10, 6))


sns.set_palette("magma")

sns.histplot(data=df, x='price_per_night', bins=10, kde=True)
plt.xlabel('Price', fontsize=14, fontweight='bold')
plt.ylabel('Frequency', fontsize=14, fontweight='bold')
plt.title('Price Distribution', fontsize=16, fontweight='bold')
plt.show()

room_type_counts = df['room_type'].value_counts()
explode = (0, 0, 0.1)
colors = ['#331D2C', '#461959','#AE445A']
plt.figure(figsize=(8, 8))
plt.pie(room_type_counts, labels=room_type_counts.index, explode=explode, autopct='%1.1f%%', shadow=True, startangle=140, colors=colors)

plt.title("Distribution of Room Types", fontweight='bold', fontsize=14)

plt.axis('equal')
plt.show()

color_palette = sns.color_palette("magma")

plt.figure(figsize=(12, 8))


sns.boxplot(data=df_filtered, x='room_type', y='price_per_night', palette=color_palette)

plt.xlabel('Room Type', fontsize=14, fontweight='bold')
plt.ylabel('Price', fontsize=14, fontweight='bold')
plt.title('Price vs. Room Type (Outliers Removed)', fontsize=16, fontweight='bold')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(12, 6))
sns.barplot(data=df, x='neighbourhood_group', y='price_per_night', palette='magma')
plt.xlabel('Neighbourhood Group', fontsize=14, fontweight='bold')
plt.ylabel('Price', fontsize=14, fontweight='bold')
plt.title('Price vs. Neighbourhood Group', fontsize=16, fontweight='bold')
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 8))
custom_palette = sns.color_palette("magma", as_cmap=True)  # Use "magma" color palette
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=True, cmap=custom_palette, fmt=".2f", linewidths=0.5)
plt.title('Correlation Heatmap', fontsize=16, fontweight='bold')
plt.show()

sns.set_palette("magma")

plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='reviews_per_month', y='price_per_night', alpha=0.5)
plt.xlabel('Reviews per Month', fontsize=14, fontweight='bold')
plt.ylabel('Price', fontsize=14, fontweight='bold')
plt.title('Price vs. Reviews per Month', fontsize=16, fontweight='bold')
plt.show()

df.head()

fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(df['number_of_reviews'], df['availability_365'], df['price'], alpha=0.5)
ax.set_xlabel('Number of Reviews', fontsize=14, fontweight='bold')
ax.set_ylabel('Availability (in days)', fontsize=14, fontweight='bold')
ax.set_zlabel('Price', fontsize=14, fontweight='bold')
ax.set_title('Price vs. Number of Reviews and Availability', fontsize=16, fontweight='bold')
plt.show()

import folium
import random
from IPython.display import display

num_markers_to_display = 200

sampled_df = df.sample(n=num_markers_to_display, random_state=42)

m = folium.Map(location=[40.7128, -74.0060], zoom_start=12, width=600, height=400)

for index, row in sampled_df.iterrows():
    folium.Marker(
        location=[row['latitude'], row['longitude']],
        popup=f"Listing: {row['name']}<br>Price: ${row['price']:.2f}",
        icon=folium.Icon(color='blue')
    ).add_to(m)

display(m)

"""# **Hypothesis Tests**

**1. Hypothesis Test: Comparing the mean prices of Private rooms and Entire home/apartment listings**

**Null Hypothesis (H0)**: The mean price of Private room listings is equal to the mean price of Entire home/apartment listings.

**Alternative Hypothesis (H1)**: The mean price of Private room listings is not equal to the mean price of Entire home/apartment listings.
"""

private_room_prices = df[df['room_type'] == 'Private room']['price']
entire_home_prices = df[df['room_type'] == 'Entire home/apt']['price']

t_statistic, p_value = stats.ttest_ind(private_room_prices, entire_home_prices)

alpha = 0.05

print("T-statistic:", t_statistic)
print("P-value:", p_value)

if p_value <= alpha:
    print("Reject the null hypothesis")
else:
    print("Fail to reject the null hypothesis")

"""it means that there is enough evidence to conclude that the mean price of Private room listings is statistically different from the mean price of Entire home/apartment listings at the 0.05 significance level



**2. Hypothesis Test:Comparing the mean prices of listings in Brooklyn and Manhattan**

**Null Hypothesis (H0):** The mean price of listings in Brooklyn is equal to the mean price of listings in Manhattan.

**Alternative Hypothesis (H1):** The mean price of listings in Brooklyn is not equal to the mean price of listings in Manhattan.
"""

brooklyn_prices = df[df['neighbourhood_group'] == 'Brooklyn']['price']
manhattan_prices = df[df['neighbourhood_group'] == 'Manhattan']['price']

t_statistic, p_value = stats.ttest_ind(brooklyn_prices, manhattan_prices)

print("T-statistic:", t_statistic)
print("P-value:", p_value)

if p_value <= alpha:
    print("Reject the null hypothesis")
else:
    print("Fail to reject the null hypothesis")

"""it means that there is enough statistical evidence to conclude that the mean prices of listings in Brooklyn and Manhattan are different at the 0.05 significance level

# **Machine Learning**

**Linear Regression**
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

features=['latitude','longitude','availability_365','minimum_nights']
target='price'

df.head()

x=df[features]
y=df[target]

x_train,x_test, y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=46)

model=LinearRegression()
model.fit(x_train,y_train)

y_pred=model.predict(x_test)

mse=mean_squared_error(y_test,y_pred)
r2=r2_score(y_test,y_pred)

print(mse)

print(r2)

"""**Gradient Boosting**

"""

from sklearn.ensemble import GradientBoostingRegressor

x_train,x_test, y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=30)

model = GradientBoostingRegressor(n_estimators=120, learning_rate = 0.1, random_state = 38)
model.fit(x_train,y_train)

y_pred=model.predict(x_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test,y_pred)

print(mse)

print(r2)

"""**Random Forest**"""

from sklearn.ensemble import RandomForestRegressor

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 33)

model = RandomForestRegressor(n_estimators=120, random_state = 38)
model.fit(x_train, y_train)

y_pred = model.predict(x_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(mse)

print(r2)

"""**Hence, the best model we can get to the above dataset is Gradient Boosting with the MSE of 50272.23**"""